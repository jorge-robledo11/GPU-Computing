{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento de procesamiento por lotes en GPU con `cudf` y `cupy`\n",
    "Este experimento busca realizar una prueba de rendimiento en la GPU utilizando `cudf` para el manejo de DataFrames y `cupy` para operaciones numéricas de gran escala. La intención es verificar la capacidad de la GPU para manejar y procesar grandes cantidades de datos mediante un enfoque de procesamiento por lotes, liberando la memoria después de cada lote para evitar saturaciones de memoria.\n",
    "\n",
    "**Configuración del experimento**\n",
    "* Total de Filas: 1,000,000,000\n",
    "* Tamaño del Lote: 100,000\n",
    "\n",
    "**Objetivos del experimento**\n",
    "1. Generar datos sintéticos que simulen un gran volumen de datos en GPU para operaciones de análisis.\n",
    "2. Ejecutar procesamiento por lotes para evitar el uso excesivo de memoria GPU, al dividir los datos en bloques más pequeños.\n",
    "3. Optimizar el uso de memoria en GPU mediante la liberación de memoria después de cada lote.\n",
    "4. Medir el tiempo total de procesamiento y el uso de memoria de la GPU durante la ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 12 18:30:47 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.02              Driver Version: 566.03         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   45C    P5             25W /  285W |    1504MiB /  12282MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as cd\n",
    "import cupy as cp\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de los experimentos\n",
    "\n",
    "# Tamaño de las matrices y el tamaño del batch\n",
    "num_rows = 1_000_000_000\n",
    "batch_size = 100_000\n",
    "\n",
    "# Definir el límite máximo de VRAM en uso antes de liberar memoria (95% de VRAM total)\n",
    "_, vram_total = cp.cuda.runtime.memGetInfo()\n",
    "vram_limit = vram_total * 0.95\n",
    "\n",
    "# Definir el número de batches en cada iteración y almacenamiento de resultados\n",
    "num_batches = num_rows // batch_size\n",
    "results = {\n",
    "    'exp1': list(),\n",
    "    'exp2': list()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de un DataFrame sintético grande\n",
    "def generate_data(rows):\n",
    "    data = {\n",
    "        'id': cp.random.randint(1, 1_000_000, size=rows),\n",
    "        'value1': cp.random.rand(rows) * 100,\n",
    "        'value2': cp.random.rand(rows) * 100,\n",
    "        'category': cp.random.randint(0, 4, size=rows)  # Genera categorías numéricas\n",
    "    }\n",
    "    # Opcional: mapea los números a letras después si es necesario\n",
    "    df = cd.DataFrame(data)\n",
    "    df['category'] = df['category'].map({0: 'A', 1: 'B', 2: 'C', 3: 'D'})\n",
    "    return df\n",
    "\n",
    "# Procesamiento por lotes en la GPU\n",
    "def batch_processing(df):\n",
    "    # Agrupación por 'category' y cálculo de media y suma\n",
    "    grouped = df.groupby('category').agg({\n",
    "        'value1': ['mean', 'sum'],\n",
    "        'value2': ['mean', 'sum']\n",
    "    })\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento 1\n",
      "Iniciando procesamiento por lotes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando lotes: 100%|██████████| 10000/10000 [01:37<00:00, 102.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesamiento completo en 97.99 segundos.\n",
      "Uso de memoria en GPU: 1.26 GB usado de 11.99 GB total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Experimento 1\\nIniciando procesamiento por lotes...')\n",
    "start_time = time()\n",
    "\n",
    "# Añadir tqdm a las iteraciones para ver el progreso\n",
    "for i in tqdm(range(num_batches), desc='Procesando lotes'):\n",
    "    # Genera un lote de datos y pasa a cudf DataFrame\n",
    "    batch_df = generate_data(batch_size)\n",
    "    # Procesamiento del lote\n",
    "    batch_result = batch_processing(batch_df)\n",
    "    results['exp2'].append(batch_result)\n",
    "    \n",
    "    # Verifica el uso de memoria y libera si se excede el límite\n",
    "    vram_free, vram_total = cp.cuda.runtime.memGetInfo()\n",
    "    vram_used = vram_total - vram_free\n",
    "    if vram_used >= vram_limit:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "print(f'Procesamiento completo en {time() - start_time:.2f} segundos.')\n",
    "# Chequeo de uso de memoria en GPU final\n",
    "vram_free, vram_total = cp.cuda.runtime.memGetInfo()\n",
    "vram_used = vram_total - vram_free\n",
    "print(f'Uso de memoria en GPU: {vram_used / (1024**3):.2f} GB usado de {vram_total / (1024**3):.2f} GB total.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"600\" height=\"400\" controls>\n",
       "  <source src=\"./exp1.mp4\" type=\"video/mp4\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Especifica la ruta al archivo de video\n",
    "HTML(\"\"\"\n",
    "<video width=\"600\" height=\"400\" controls>\n",
    "  <source src=\"./exp1.mp4\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento 2\n",
      "Iniciando procesamiento por lotes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando lotes: 100%|██████████| 10000/10000 [01:14<00:00, 133.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesamiento completo en 74.65 segundos.\n",
      "Uso de memoria en GPU: 1.29 GB usado de 11.99 GB total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Experimento 2\\nIniciando procesamiento por lotes...')\n",
    "start_time = time()\n",
    "\n",
    "# Añadir tqdm a las iteraciones para ver el progreso\n",
    "for i in tqdm(range(num_batches), desc='Procesando lotes'):\n",
    "    # Genera un lote de datos y pasa a cudf DataFrame\n",
    "    batch_df = generate_data(batch_size)\n",
    "    # Procesamiento del lote\n",
    "    batch_result = batch_processing(batch_df)\n",
    "    # Guardamos el resultado para evitar que sea eliminado de la memoria\n",
    "    results['exp2'].append(batch_result)\n",
    "    # Forzamos que cupy libere memoria no utilizada\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "print(f'Procesamiento completo en {time() - start_time:.2f} segundos.')\n",
    "\n",
    "# Chequeo de uso de memoria en GPU final\n",
    "vram_free, vram_total = cp.cuda.runtime.memGetInfo()\n",
    "vram_used = vram_total - vram_free\n",
    "print(f'Uso de memoria en GPU: {vram_used / (1024**3):.2f} GB usado de {vram_total / (1024**3):.2f} GB total.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"600\" height=\"400\" controls>\n",
       "  <source src=\"./exp2.mp4\" type=\"video/mp4\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Especifica la ruta al archivo de video\n",
    "HTML(\"\"\"\n",
    "<video width=\"600\" height=\"400\" controls>\n",
    "  <source src=\"./exp2.mp4\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-gpu-ciH94wyv-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
